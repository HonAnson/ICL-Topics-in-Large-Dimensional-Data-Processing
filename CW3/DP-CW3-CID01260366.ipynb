{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6b0940",
   "metadata": {},
   "source": [
    "# Coursework 3\n",
    "\n",
    "### PLAGIARISM/COLLUSION DECLARATION\n",
    "\n",
    " \n",
    "\n",
    "Coursework submitted for assessment must be the original work of you and your group. Assignments are subjected to regular checks for plagiarism and/or collusion. Plagiarism is the presentation of another personâ€™s thoughts or words (those outside your group) as if they were your own. Collusion involves obtaining help from someone outside your group to complete your work. In preparing your coursework, you should not seek help, or copy from any other person or source, including the\n",
    "\n",
    "Internet, without proper and explicit acknowledgement.\n",
    "\n",
    " \n",
    "\n",
    "There is a procedure in place for you to declare individual contributions within your group for courswork. You must declare the contributions fairly and accurately.\n",
    "\n",
    " \n",
    "\n",
    "You must not disclose your solutions or insights related to coursework with anyone else, including future students or the Internet.\n",
    "\n",
    " \n",
    "\n",
    "By acknowledging the the statements above, you are declaring that both this and all subsequent pieces of coursework are, and will remain, the original work of you and your group.\n",
    "\n",
    " \n",
    "\n",
    "* Submissions will not be accepted without the aforementioned declaration.\n",
    "\n",
    " \n",
    "\n",
    "* Members of a group are deemed to have collective responsibility for the integrity for work submitted and are liable for any penalty imposed, proportionate to their contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "156ebb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2,FileIO\n",
    "using LinearAlgebra, Wavelets, FFTW, LinearMaps, IterativeSolvers, LinearOperators, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CourseWork_3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Base.@kwdef mutable struct CourseWork_3\n",
    "    \n",
    "    CID::Int\n",
    "    Plagiarism_declare::Union{Missing,Bool}\n",
    "    Demo_willing::Union{Missing,Bool}\n",
    "    \n",
    "    # 8.1 Proximal Operator\n",
    "    \n",
    "    Q8_1_a_data_z::Vector\n",
    "    Q8_1_a_data_gamma::Float64\n",
    "    \n",
    "    Q8_1_a_ans_x::Union{Missing,Vector}\n",
    "    \n",
    "    Q8_1_b_data_z::Vector\n",
    "    Q8_1_b_data_gamma::Float64\n",
    "    \n",
    "    Q8_1_b_ans_x::Union{Missing,Vector}\n",
    "    \n",
    "    # 8.2  MRI CS Recovery: ADMM\n",
    "    \n",
    "    Q8_2_data_y::Vector\n",
    "    Q8_2_data_Omega::Matrix\n",
    "    Q8_2_data_X2_ini::Matrix\n",
    "    Q8_2_data_X3_ini::Matrix\n",
    "    Q8_2_data_X4_ini::Matrix\n",
    "    Q8_2_data_X5_ini::Matrix\n",
    "    Q8_2_data_U2_ini::Matrix\n",
    "    Q8_2_data_U3_ini::Matrix\n",
    "    Q8_2_data_U4_ini::Matrix\n",
    "    Q8_2_data_U5_ini::Matrix\n",
    "    Q8_2_data_lambda1::Float64\n",
    "    Q8_2_data_lambda2::Float64\n",
    "    Q8_2_data_lambda3::Float64\n",
    "    Q8_2_data_rho::Float64\n",
    "    \n",
    "    Q8_2_1_ans_X1::Union{Missing,Matrix}\n",
    "    \n",
    "    Q8_2_2_ans_X2::Union{Missing,Matrix}\n",
    "    Q8_2_2_ans_X3::Union{Missing,Matrix}\n",
    "    Q8_2_2_ans_X4::Union{Missing,Matrix}\n",
    "    Q8_2_2_ans_X5::Union{Missing,Matrix}\n",
    "    \n",
    "    Q8_2_3_ans_U2::Union{Missing,Matrix}\n",
    "    Q8_2_3_ans_U3::Union{Missing,Matrix}\n",
    "    Q8_2_3_ans_U4::Union{Missing,Matrix}\n",
    "    Q8_2_3_ans_U5::Union{Missing,Matrix}\n",
    "    \n",
    "    Q8_2_4_ans_Xhat::Union{Missing,Matrix}\n",
    "    \n",
    "    # 8.3. Blind Deconvolution: Convex Relaxation\n",
    "    \n",
    "    Q8_3_data_y::Vector\n",
    "    Q8_3_data_X2_ini::Matrix\n",
    "    Q8_3_data_X3_ini::Matrix\n",
    "    Q8_3_data_X4_ini::Matrix\n",
    "    Q8_3_data_U2_ini::Matrix\n",
    "    Q8_3_data_U3_ini::Matrix\n",
    "    Q8_3_data_U4_ini::Matrix\n",
    "    Q8_3_data_lambda1::Float64\n",
    "    Q8_3_data_lambda2::Float64\n",
    "    Q8_3_data_lambda3::Float64\n",
    "    \n",
    "    Q8_3_2_ans_X1::Union{Missing,Matrix}\n",
    "    \n",
    "    Q8_3_3_ans_X2::Union{Missing,Matrix}\n",
    "    Q8_3_3_ans_X3::Union{Missing,Matrix}\n",
    "    Q8_3_3_ans_X4::Union{Missing,Matrix}\n",
    "    \n",
    "    Q8_3_4_ans_U2::Union{Missing,Matrix}\n",
    "    Q8_3_4_ans_U3::Union{Missing,Matrix}\n",
    "    Q8_3_4_ans_U4::Union{Missing,Matrix}\n",
    "    \n",
    "    Q8_3_5_ans_Xhat::Union{Missing,Matrix}\n",
    "    \n",
    "    # Blind Deconvolution\n",
    "    \n",
    "    Q8_4_data_y::Vector\n",
    "    Q8_4_data_x1ini::Vector\n",
    "    Q8_4_data_x2ini::Vector\n",
    "    Q8_4_data_x3ini::Vector\n",
    "    Q8_4_data_h1ini::Vector\n",
    "    Q8_4_data_h2ini::Vector\n",
    "    Q8_4_data_alpha::Float64\n",
    "    \n",
    "    Q8_4_1_a_ans_H::Union{Missing,Matrix}\n",
    "    Q8_4_1_b_ans_tau::Union{Missing,Float64}\n",
    "    Q8_4_1_c_ans_x1::Union{Missing,Vector}\n",
    "    Q8_4_1_c_ans_x2::Union{Missing,Vector}\n",
    "    Q8_4_1_c_ans_x3::Union{Missing,Vector}\n",
    "    Q8_4_1_d_ans_subg::Union{Missing,Vector}\n",
    "    \n",
    "    Q8_4_2_a_ans_H::Union{Missing,Matrix}\n",
    "    Q8_4_2_b_ans_tau::Union{Missing,Float64}\n",
    "    Q8_4_2_c_ans_h1::Union{Missing,Vector}\n",
    "    Q8_4_2_c_ans_h2::Union{Missing,Vector}\n",
    "    Q8_4_2_d_ans_subg::Union{Missing,Vector}\n",
    "    \n",
    "    Q8_4_3_ans_subg::Union{Missing,Vector}\n",
    "    \n",
    "    Q8_4_4_ans_x1::Union{Missing,Vector}\n",
    "    Q8_4_4_ans_h1::Union{Missing,Vector}\n",
    "    \n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "30132ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and upload data from JLD file, refer to https://juliaio.github.io/JLD2.jl/dev/ \n",
    "\n",
    "# Example\n",
    "A = JLD2.load(\"Chin Young Anson, Hon1260366StudentFile.jld2\");\n",
    "A = A[ \"CourseWork_3\" ];\n",
    "A.Demo_willing = true;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "jldopen(\"Chin Young Anson, Hon1260366StudentFile.jld2\", \"w\") do file\n",
    "    write(file, \"CourseWork_3\", A)\n",
    " end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861a416",
   "metadata": {},
   "source": [
    "## 8.1. Proximal Operator (Continued)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b22aba",
   "metadata": {},
   "source": [
    "### 1. (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "ee609657",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = A.Q8_1_a_data_z\n",
    "gamma = A.Q8_1_a_data_gamma\n",
    "\n",
    "# Differentiable least square problem.\n",
    "# Differentiating with respect to x and then set to zero gives:\n",
    "output = z / (gamma + 1)\n",
    "\n",
    "### 8.1a Assign to answer: \n",
    "A.Q8_1_a_ans_x = output;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfd18e",
   "metadata": {},
   "source": [
    "### 1. (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "96ea13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = A.Q8_1_b_data_z\n",
    "gamma = A.Q8_1_b_data_gamma\n",
    "\n",
    "function prox_eucl_norm(z, gamma)\n",
    "    # Use closed form solution for L2 norm \n",
    "    temp = 1-gamma/norm(z)  \n",
    "    temp2 = maximum([0,temp])       # Choose maximum of 0 vs 1-gamma/norm(z)\n",
    "    return temp2*z\n",
    "end\n",
    "output = prox_eucl_norm(z, gamma)\n",
    "\n",
    "### 8.1b Assign to answer: \n",
    "A.Q8_1_b_ans_x = output;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46463fa",
   "metadata": {},
   "source": [
    "## 8.2. MRI CS Recovery: ADMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bae6e",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "e605f2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c78f0e",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "e1412b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d2bce10",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "ee090674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77c36de1",
   "metadata": {},
   "source": [
    "## 8.3. Blind Deconvolution: Convex Relaxation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e41bde",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "630f68f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A.Q8_3_data_y      \n",
    "A.Q8_3_data_X2_ini \n",
    "A.Q8_3_data_X3_ini \n",
    "A.Q8_3_data_X4_ini \n",
    "A.Q8_3_data_U2_ini \n",
    "A.Q8_3_data_U3_ini \n",
    "A.Q8_3_data_U4_ini \n",
    "A.Q8_3_data_lambda1\n",
    "A.Q8_3_data_lambda2\n",
    "A.Q8_3_data_lambda3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d56bb",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "9a058116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526d9c1c",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "9beb3748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "febd0c11",
   "metadata": {},
   "source": [
    "## 8.4. Blind Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24e1db",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "fe31f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = A.Q8_4_data_y    \n",
    "x1ini_data =  A.Q8_4_data_x1ini\n",
    "x2ini_data =  A.Q8_4_data_x2ini\n",
    "x3ini_data =  A.Q8_4_data_x3ini\n",
    "h1ini_data =  A.Q8_4_data_h1ini\n",
    "h2ini_data =  A.Q8_4_data_h2ini\n",
    "alpha_data =  A.Q8_4_data_alpha \n",
    "lambda_data = 0.1\n",
    "\n",
    "### Adjust dimension for y\n",
    "y_new = zeros(209)\n",
    "y_new[1:200] = y_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4362d",
   "metadata": {},
   "source": [
    "Create Necessary Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convolution (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Create matrix operator D for TV operation\n",
    "m = size(x1ini_data)[1]\n",
    "I_200 = Matrix{Float64}(I, m, m)    # Create identity square matrix of size m*m, size of x1\n",
    "I_trunk_top = I_200[2:m,:]          # Truncate top row of I\n",
    "I_trunk_bottom = I_200[1:m-1,:]     # Truncate bottom row of I\n",
    "D = I_trunk_top - I_trunk_bottom;   # TV matrix operator 'D' = top truncated iden matrix - bottom truncated iden matrix\n",
    "\n",
    "# Also, use 4.3.3a to obtain convolution matrix operators\n",
    "function Convolution(x,h)\n",
    "    n=length(x)\n",
    "    m=length(h)\n",
    "    C_h=zeros(n+m-1,n)\n",
    "    for i in 1:(n+m-1)\n",
    "        for j in 1:n\n",
    "            if i-j>=0 && i-j<m\n",
    "                C_h[i,j]=h[i-j+1]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    C_star=transpose(C_h)\n",
    "    return C_h,C_star\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb6dbf",
   "metadata": {},
   "source": [
    "Closed Form Solutions for Proximal Opeartors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "55acc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Closed form solution from 6.1d\n",
    "function closed_form_0norm(z,gamma)\n",
    "    # find the absolute values of z\n",
    "    z_abs = abs.(z)\n",
    "    min_error = 1.0e9\n",
    "    final_x = zeros(length(z))\n",
    "\n",
    "    # iterate through till the length of z\n",
    "    for k_i in 1:length(z)\n",
    "        x = zeros(length(z))\n",
    "\n",
    "        # find the indices of k_i largest absolute values of z\n",
    "        top_ki_indices = sortperm(z_abs, rev=true)[1:min(k_i, length(z_abs))]\n",
    "\n",
    "        # copy the largest values of z to x\n",
    "        x[top_ki_indices] = z[top_ki_indices]\n",
    "        error = norm(x, 0) + (1/(2*gamma) * (norm((x-z),2)^2))\n",
    "        \n",
    "        # println(\"Error: \", error)\n",
    "        if (error < min_error)\n",
    "            min_error = error\n",
    "            final_x = x\n",
    "        end\n",
    "    end\n",
    "    return final_x\n",
    "end\n",
    "\n",
    "### Closed form solution from 6.1h\n",
    "function closed_form_normis1(z,gamma)\n",
    "    x = z / norm(z, 2)\n",
    "    return x\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05621146",
   "metadata": {},
   "source": [
    "8.4.1a: Compute and assemble Hessian Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create I_199 for computing H_33\n",
    "I_199 = Matrix{Float64}(I, m-1, m-1);\n",
    "\n",
    "# Compute Each Block in Hessian Matrix using differenciation\n",
    "H_11 = alpha_data*I_200 + alpha_data*(D'*D)  # differenciate w.r.t. x1 twice \n",
    "H_12 = -alpha_data*I_200                     # differenciate w.r.t. x1 then x2\n",
    "H_13 = -alpha_data*D'                        # so on\n",
    "H_22 = alpha_data*I_200\n",
    "H_23 = zeros(m,m-1)\n",
    "H_33 = alpha_data*I_199;\n",
    "\n",
    "# Stack each block back to 1 Hessian matrix\n",
    "H_r1 = hcat(H_11, H_12, H_13)\n",
    "H_r2 = hcat(H_12', H_22, H_23)\n",
    "H_r3 = hcat(H_13',H_23', H_33 )\n",
    "Hess = vcat(H_r1, H_r2, H_r3)\n",
    "\n",
    "### 8.4.1a Assign to Answer\n",
    "A.Q8_4_1_a_ans_H = Hess;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0ac0e",
   "metadata": {},
   "source": [
    "8.4.1b: Get Upper Bounds  \n",
    "NOTE: Use the smallest upperbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. The Liptich constant is just the largest eigen value of each hessian matrix for double differenciation of x1, x2 and x3\n",
    "# As svd() automitally sort the eigen values, we simply choose the first eigen value using svd() function\n",
    "_, e1, _ = svd(Hess[1:200,1:200])\n",
    "l1 = e1[1]\n",
    "_, e2, _ = svd(Hess[201:400,201:400])\n",
    "l2 = e2[1]\n",
    "_, e3, _ = svd(Hess[401:599,401:599])\n",
    "l3 = e3[1]\n",
    "\n",
    "# Upper bound = 1/Liptich constant\n",
    "u1 = 1/l1\n",
    "u2 = 1/l2\n",
    "u3 = 1/l3\n",
    "\n",
    "### 8.4.1b Assign to Answer\n",
    "A.Q8_4_1_b_ans_tau = minimum([u1, u2, u3]); # Return smallest upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6deb545",
   "metadata": {},
   "source": [
    "8.4.1c: update x1:3 with one step proximal gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make function to run proximal gradient of 1 step for x1, x2 and x3\n",
    "function prox_grad_x1(x1,x2,x3,h1,gamma)\n",
    "    # First, get the matrix operator 'H' for convolution:\n",
    "    H, _ = Convolution(x1, h1)\n",
    "\n",
    "    # Obtain gradient of \"Smooth\" part of proximal operator for x1\n",
    "    # differenciate: 1/2 * norm(y - x1 conv h1) + alpha/2 * norm(x2-x1) + alpha/2 * norm(x3-D*x1), w.r.t. x1 to get grad\n",
    "    grad = alpha_data*(x1-x2+D'*(D*x1-x3))  # NOTE: D is TV operator\n",
    "    z = x1 - gamma * grad \n",
    "\n",
    "    # We solve for x1 from the following least square problem, which is the proximal operator for x1:\n",
    "    # min 1/2* x1'(H'H+(1/gamma)I)x1 + (-H'y-z)'x1\n",
    "    # use cg to solve least square problem:\n",
    "    op = LinearOperator(H'*H+(1/gamma)*I_200)  # LinearOpeartor for better accuracy compared to LinearMap\n",
    "    b = -(H'*y_new+z)'\n",
    "    output = cg(op, b, maxiter=1000)\n",
    "    return output, grad\n",
    "end\n",
    "\n",
    "function prox_grad_x2(x1,x2,x3,gamma)\n",
    "\n",
    "    # Obtain gradient of \"Smooth\" part of proximal operator for x2\n",
    "    # differenciate: alpha/2 * norm(x2-x1) w.r.t. x2 to get grad\n",
    "    grad = alpha_data*(x2-x1)\n",
    "    z = x2 - gamma*grad\n",
    "\n",
    "    # Solve the following proximal operator\n",
    "    # min delta(norm(x2) = 1) + 1/2gamma *norm(x2-z)\n",
    "    #####\n",
    "    # Using solution from 6.1h:\n",
    "    output = closed_form_normis1(z,gamma)\n",
    "    return output, grad\n",
    "\n",
    "end\n",
    "\n",
    "function prox_grad_x3(x1,x2,x3,gamma)\n",
    "    # Obtain gradient of \"Smooth\" part of proximal operator for x3ini_data\n",
    "    grad = alpha_data*(x3 - D*x1)\n",
    "    z = x3 - gamma*grad\n",
    "\n",
    "    # We then have proximal operator:\n",
    "    # min lambda*norm(x3,0) + 1/2gamma *norm(x3-z)\n",
    "    #####\n",
    "    output = closed_form_0norm(z,gamma)\n",
    "    return output, grad\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92693903",
   "metadata": {},
   "source": [
    "We can also implement closed form minization for x1, x2 and x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "2f34d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Closed form could be use to update x1, x2 and x3 in alternating minization\n",
    "function closed_form_x1(x1,x2,x3,h1)\n",
    "    H, _ = Convolution(x1, h1)\n",
    "    A = H'*H + alpha_data*I_200 + alpha_data*D'*D\n",
    "    op = LinearOperator(A)\n",
    "    b = -(H'*y_new+x2+D'*x3)\n",
    "    output = cg(op, b, maxiter=1000)\n",
    "    return output\n",
    "end\n",
    "\n",
    "function closed_form_x2(x1)\n",
    "    output = x1/norm(x1)\n",
    "    return output\n",
    "end\n",
    "\n",
    "function closed_form_x3(x1)\n",
    "    z = D*x1\n",
    "    gamma = lambda_data / alpha_data\n",
    "    return closed_form_0norm(z,gamma)\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "6feebbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply Proximal gradient\n",
    "# obtain initial values\n",
    "gamma_x = 0.8*minimum([u1, u2, u3])   # choose step size as 0.8*upper bound\n",
    "x1 = x1ini_data\n",
    "x2 = x2ini_data\n",
    "x3 = x3ini_data\n",
    "h1 = h1ini_data\n",
    "h2 = h2ini_data\n",
    "\n",
    "x1,grad_x1_1 = prox_grad_x1(x1,x2,x3,h1,gamma_x) # update x1\n",
    "x2,grad_x2_1 = prox_grad_x2(x1,x2,x3,gamma_x) # update x2\n",
    "x3,grad_x3_1 = prox_grad_x3(x1,x2,x3,gamma_x) # update x3\n",
    "\n",
    "### 8.4.1c Assign to answer:\n",
    "A.Q8_4_1_c_ans_x1 = x1;\n",
    "A.Q8_4_1_c_ans_x2 = x2;\n",
    "A.Q8_4_1_c_ans_x3 = x3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4def29e",
   "metadata": {},
   "source": [
    "8.4.1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "022a0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that:\n",
    "# Using lecture notes, subgradient of F could be given by:\n",
    "# del(f_l) - del(f_l-1) - 1/gamma (x_l - x_l-1)\n",
    "\n",
    "function subg_x(x1, x2, x3, h1)\n",
    "    subg_x1 = alpha_data*(x1-x2+D'*(D*x1-x3))\n",
    "    subg_x2 = alpha_data*(x2-x1)\n",
    "    subg_x3 = alpha_data*(x3 - D*x1)\n",
    "    subg = vcat(subg_x1, subg_x2,subg_x3)\n",
    "    return subg\n",
    "end\n",
    "\n",
    "_,grad_x1_2 = prox_grad_x1(x1,x2,x3,h1,gamma_x) # Not updating x1\n",
    "_,grad_x2_2 = prox_grad_x2(x1,x2,x3,gamma_x) # Not updating x2\n",
    "_,grad_x3_2 = prox_grad_x3(x1,x2,x3,gamma_x) # Not updating x3\n",
    "\n",
    "subg_x1 = grad_x1_2 - grad_x1_1  - (1/gamma_x) * (x1 - x1ini_data)\n",
    "subg_x2 = grad_x2_2 - grad_x2_1  - (1/gamma_x) * (x2 - x2ini_data)\n",
    "subg_x3 = grad_x3_2 - grad_x3_1  - (1/gamma_x) * (x3 - x3ini_data)\n",
    "\n",
    "\n",
    "### 8.4.1d Assign to answer:\n",
    "# A.Q8_4_1_d_ans_subg = subg_x(x1, x2, x3, h1);\n",
    "A.Q8_4_1_d_ans_subg = vcat(subg_x1,subg_x2,subg_x3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257491c3",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dfb587",
   "metadata": {},
   "source": [
    "8.4.2a: hessian matrix of h1 and h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "76f2ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, Compute each block in Hessian Matrix using differenciation\n",
    "n = length(h1ini_data)\n",
    "I_10 = Matrix{Float64}(I, n, n) # Create 10x10 identity matrix\n",
    "H_11 = alpha_data * I_10            # differenciate w.r.t. x1 twice \n",
    "H_12 = -alpha_data * I_10           # differenciate w.r.t. x1 then x2\n",
    "H_21 = -alpha_data * I_10\n",
    "H_22 = alpha_data * I_10\n",
    "\n",
    "# Stack them to 1 Hessian matrix\n",
    "H_r1 = hcat(H_11,H_12)\n",
    "H_r2 = hcat(H_21,H_22)\n",
    "Hess = vcat(H_r1, H_r2)\n",
    "\n",
    "### 8.4.2a Assign to Answer\n",
    "A.Q8_4_2_a_ans_H = Hess;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26927b6",
   "metadata": {},
   "source": [
    "8.4.2b: Find Upperbound for proximal gradient for h1:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "4fee8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, find Liptich constant for hessian matrix:\n",
    "# Actually its just alpha, \n",
    "# but still, choose largest eigen value for good practice\n",
    "_, e1, _ = svd(H_11)\n",
    "l1 = e1[1]\n",
    "_, e2, _ = svd(H_12)\n",
    "l2 = e2[1]\n",
    "\n",
    "# Upper bound = 1/Lpitich constant\n",
    "upb = 1/maximum([l1,l2])\n",
    "\n",
    "### 8.4.2b Assign to answer:\n",
    "A.Q8_4_2_b_ans_tau = upb;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05150914",
   "metadata": {},
   "source": [
    "8.4.2c: Update h1:2 using one step of proximal operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "a49d409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prox_grad_h2 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Make function to run proximal gradient of 1 step for h1, h2\n",
    "function prox_grad_h1(x1,h1,h2,gamma)\n",
    "    # Get convolution operator for h1:\n",
    "    H,_ = Convolution(h1,x1)\n",
    "\n",
    "    # Obtain gradient for \"smooth\" part\n",
    "    grad = alpha_data*(h1-h2)\n",
    "    z = h1 - gamma*grad\n",
    "\n",
    "    # Solve proximal operator, which is the following least square problem:\n",
    "    # min 1/2* h1'(H'H+(1/gamma)I)h1 + (-H'y-z)'x1\n",
    "    op = LinearOperator(H'*H+(1/gamma)*I_10)\n",
    "    b = -H'*y_new - (1/gamma)*z\n",
    "    output = cg(op, b, maxiter=1000)\n",
    "    return output, grad\n",
    "end\n",
    "\n",
    "function prox_grad_h2(h1, h2, gamma)\n",
    "    # Obtain gradient of \"smooth\" part through differenciation\n",
    "    grad = alpha_data*(h2-h1)\n",
    "    z = h2 - gamma*grad\n",
    "    \n",
    "    # Solve proximal operator with closed form solution\n",
    "    #####\n",
    "    # Using solution from 6.1d:\n",
    "    output = closed_form_0norm(z,gamma)\n",
    "    return output, grad\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd16770",
   "metadata": {},
   "source": [
    "Here, Also implement closed form minization for h1 and h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "19f31363",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Closed form for updating h1 and h2\n",
    "function closed_form_h1(x1, h1, h2)\n",
    "    # Get convolution operator for h1:\n",
    "    H,_ = Convolution(h1,x1)\n",
    "    # Solve least square\n",
    "    A = H'*H + alpha_data*I_10\n",
    "    op = LinearOperator(A)\n",
    "    b = -H'*y_new - alpha_data*h2\n",
    "    output = cg(op, b, maxiter=1000)\n",
    "    return output\n",
    "end\n",
    "\n",
    "function closed_form_h2(h1, h2)\n",
    "    z = h1\n",
    "    gamma = lambda_data / alpha_data\n",
    "    return closed_form_0norm(z,gamma)\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "3579799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose step size as 0.8 upperbound:\n",
    "gamma_h = 0.8*upb\n",
    "\n",
    "# Run 1 step proximal operator to update h1 and h2\n",
    "h1, grad_h1_1 = prox_grad_h1(x1,h1,h2,gamma_h)\n",
    "h2, grad_h2_1 = prox_grad_h2(h1, h2, gamma_h)\n",
    "\n",
    "### 8.4.2c Assign answer:\n",
    "A.Q8_4_2_c_ans_h1 = h1\n",
    "A.Q8_4_2_c_ans_h2 = h2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f0c6c",
   "metadata": {},
   "source": [
    "8.4.2d: Subgradient with respect to h1:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subg for h1 is obained through differenciation, since h1 is convex\n",
    "# We can differenciate the followign term with respect to h1 and get the subgradient:\n",
    "# (1/2)*h1'*(H'H+alpha*I) + alpha/2 * norm(h2-h1,2)\n",
    "# Differenciating gives:\n",
    "function subg_h(h1, h2, x1)\n",
    "    # Get convolution operator\n",
    "    H,_ = Convolution(h1,x1)\n",
    "    subg_h1 = (H'*H*h1 - 2*H'*y_new) + alpha_data*(h1-h2)\n",
    "    subg_h2 = alpha_data * (h2-h1)\n",
    "    subg = vcat(subg_h1, subg_h2)\n",
    "    return subg\n",
    "end\n",
    "\n",
    "_,grad_h1_2 = prox_grad_h1(x1,h1,h2,gamma_h) # Not updating h1\n",
    "_,grad_h2_2 = prox_grad_h2(h1, h2, gamma_h) # Not updating h2\n",
    "\n",
    "\n",
    "subg_h1 = grad_h1_2 - grad_h1_1  - (1/gamma_h) * (h1 - h1ini_data)\n",
    "subg_h2 = grad_h2_2 - grad_h2_1  - (1/gamma_h) * (h2 - h2ini_data)\n",
    "\n",
    "\n",
    "### 8.4.2d Assign to answer:\n",
    "# A.Q8_4_2_d_ans_subg = subg_h(h1, h2, x1);\n",
    "A.Q8_4_2_d_ans_subg = vcat(subg_h1, subg_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7a294",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5869b",
   "metadata": {},
   "source": [
    "3. Evaluate subgradient w.r.t. x1:3 again, using updated x1:3 and h1:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,grad_x1_2 = prox_grad_x1(x1,x2,x3,h1,gamma_x) # Not updating x1\n",
    "_,grad_x2_2 = prox_grad_x2(x1,x2,x3,gamma_x) # Not updating x2\n",
    "_,grad_x3_2 = prox_grad_x3(x1,x2,x3,gamma_x) # Not updating x3\n",
    "\n",
    "subg_x1 = grad_x1_2 - grad_x1_1  - (1/gamma_x) * (x1 - x1ini_data)\n",
    "subg_x2 = grad_x2_2 - grad_x2_1  - (1/gamma_x) * (x2 - x2ini_data)\n",
    "subg_x3 = grad_x3_2 - grad_x3_1  - (1/gamma_x) * (x3 - x3ini_data)\n",
    "\n",
    "\n",
    "### 8.4.3 Assign to answer:\n",
    "# A.Q8_4_3_ans_subg = subg_x(x1, x2, x3, h1);\n",
    "A.Q8_4_3_ans_subg = vcat(subg_x1, subg_x2, subg_x3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b9d41e",
   "metadata": {},
   "source": [
    "Complete Alternating minization, using at most 500 iteration, feel free to tunne hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbd04aa",
   "metadata": {},
   "source": [
    "Here, we implement proximal gradient descent as per question requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Variables to be optimized:\n",
    "x1 = x1ini_data\n",
    "x2 = x2ini_data\n",
    "x3 = x3ini_data\n",
    "h1 = h1ini_data\n",
    "h2 = h2ini_data\n",
    "\n",
    "### Tunnable hyperparameter:\n",
    "# alpha_data += 200.0 #15\n",
    "# lambda_data += 50  #0.1\n",
    "\n",
    "#####################\n",
    "\n",
    "# We now run alternating minization for 500 iterations:\n",
    "iter = 500\n",
    "epsilon = 1e-6\n",
    "loss = zeros(iter)\n",
    "g_x1 = zeros(iter)\n",
    "g_x2 = zeros(iter)\n",
    "g_x3 = zeros(iter)\n",
    "g_h1 = zeros(iter)\n",
    "g_h2 = zeros(iter)\n",
    "subg_x_rec = zeros(iter)\n",
    "subg_h_rec = zeros(iter)\n",
    "\n",
    "# NOTE: Stopping criteria of at most 500 iteration is incooperated in max number of loop variable\n",
    "for i in 1:iter\n",
    "    # store original x1 before updating for subgradient calculation\n",
    "    x1_old = x1\n",
    "    x2_old = x2\n",
    "    x3_old = x3\n",
    "    h1_old = h1\n",
    "    h2_old = h2\n",
    "\n",
    "    # # update x1:3\n",
    "    x1,  = prox_grad_x1(x1,x2,x3,h1,gamma_x) # update x1\n",
    "    x2 = prox_grad_x2(x1,x2,x3,gamma_x) # update x2\n",
    "    x3 = prox_grad_x3(x1,x2,x3,gamma_x) # update x3\n",
    "    \n",
    "    # # update h1:3\n",
    "    h1 = prox_grad_h1(x1,h1,h2,gamma_h)\n",
    "    h2 = prox_grad_h2(h1,h2,gamma_h)\n",
    "\n",
    "    # calculate loss for plotting:\n",
    "    H, _ = Convolution(x1, h1)\n",
    "    loss[i] =   (1/2)*norm(y_new - H*x1) + \n",
    "                lambda_data*norm(x3,0) +\n",
    "                lambda_data*norm(h2,0) +\n",
    "                (alpha_data/2)*norm(x2-x1) +\n",
    "                (alpha_data/2)*norm(x3-D*x1) +\n",
    "                (alpha_data/2)*norm(h2-h1)\n",
    "                \n",
    "    subg_x_rec[i] = norm(subg_x(x1, x2, x3, h1))\n",
    "    subg_h_rec[i] = norm(subg_h(h1, h2, x1))\n",
    "\n",
    "    # exit criteria: difference objective function between current and last iteration less than epsilon \n",
    "    # if i > 2 && abs(loss[i] - loss[i-1]) < epsilon  \n",
    "    #     break\n",
    "    # end \n",
    "end\n",
    "\n",
    "### Assign to answer:\n",
    "A.Q8_4_4_ans_x1 = x1\n",
    "A.Q8_4_4_ans_h1 = h1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646c9f9",
   "metadata": {},
   "source": [
    "Use the following plot to observe result for hyper paremeter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528db069",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = x1*h1'\n",
    "### Plot the thing and have a look\n",
    "magnitude = abs.(X_final)\n",
    "\n",
    "# Rotate the data for plotting\n",
    "magnitude_rotated = magnitude[end:-1:1, end:-1:1]\n",
    "\n",
    "# Plot the magnitude\n",
    "p1 = heatmap(magnitude_rotated, color=:grays, title=\"Magnitude\")\n",
    "plot(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2b07a",
   "metadata": {},
   "source": [
    "We also implement closed form alternate minization to compare optimisation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dfe4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Variables to be optimized:\n",
    "x1 = x1ini_data\n",
    "x2 = x2ini_data\n",
    "x3 = x3ini_data\n",
    "h1 = h1ini_data\n",
    "h2 = h2ini_data\n",
    "\n",
    "### Tunnable hyperparameter:\n",
    "# alpha_data += 200.0 #15\n",
    "# lambda_data += 50  #0.1\n",
    "\n",
    "#####################\n",
    "\n",
    "# We now run alternating minization for 500 iterations:\n",
    "iter = 500\n",
    "epsilon = 1e-6\n",
    "loss = zeros(iter)\n",
    "\n",
    "# NOTE: Stopping criteria of at most 500 iteration is incooperated in max number of loop variable\n",
    "for i in 1:iter\n",
    "    \n",
    "\n",
    "    # Closed form implementation\n",
    "    x1 = closed_form_x1(x1,x2,x3,h1)\n",
    "    x2 = closed_form_x2(x1)\n",
    "    x3 = closed_form_x3(x1)\n",
    "    h1 = closed_form_h1(x1, h1, h2)\n",
    "    h2 = closed_form_h2(h1, h2)\n",
    "\n",
    "    # calculate loss for plotting:\n",
    "    H, _ = Convolution(x1, h1)\n",
    "    loss[i] =   (1/2)*norm(y_new - H*x1) + \n",
    "                lambda_data*norm(x3,0) +\n",
    "                lambda_data*norm(h2,0) +\n",
    "                (alpha_data/2)*norm(x2-x1) +\n",
    "                (alpha_data/2)*norm(x3-D*x1) +\n",
    "                (alpha_data/2)*norm(h2-h1)\n",
    "                \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "jldopen(\"Chin Young Anson, Hon1260366StudentFile.jld2\", \"w\") do file\n",
    "    write(file, \"CourseWork_3\", A)\n",
    " end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
